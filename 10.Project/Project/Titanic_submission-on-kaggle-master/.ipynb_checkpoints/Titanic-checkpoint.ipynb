{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![picture.jpg](image/picture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic was a British passenger liner operated by the White Star Line that sank in the North Atlantic Ocean in the early morning hours of 15 April 1912, after striking an iceberg during her maiden voyage from Southampton to New York City. Of the estimated 2,224 passengers and crew aboard, more than 1,500 died, making the sinking one of modern history's deadliest peacetime commercial marine disasters."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "So we need to first study of our data\n",
    "1 - PassengerId - Column does not depend on survive.\n",
    "2 - Pclacss - it's needed for prediction . \n",
    "4 - Name - it's not useful for our prediction.\n",
    "5 - Sex - Male/ Female depends on survived because female always get a first chance. \n",
    "6 - Age - Age depends on survivde .\n",
    "7 - SibSp - Having siblings/spouse depends on survived .\n",
    "8 - Parch - Number of childs depends on survived .\n",
    "9 - Ticket - Ticket not create impact on survived .\n",
    "10 - Fare - Fare create impact om survived because who have a costly tickets ,that person have more chance to get first in lifeboat .\n",
    "11 - Cabin - Cabin have more null values and its not create any impact on survived .\n",
    "12 - Embarked - it's create impact on survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contents"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Import Data\n",
    "2.Visualizing data\n",
    "3.Cleaning data\n",
    "4.Choosing Best Model .\n",
    " \n",
    "    Logistic Regression .\n",
    "    Support Vector Machines (SVC) .\n",
    "    Linear SVC .\n",
    "    k-Nearest Neighbor (KNN) .\n",
    "    Decision Tree .\n",
    "    Random Forest .\n",
    "    Naive Bayes (GaussianNB) .\n",
    "    .\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "sns.set() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking into the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total rows and columns (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing Dataset (train data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This shows that there are duplicate Ticket number and Cabins shared. The highest number of duplicate ticket number is \"CA. 2343\". It has been repeated 7 times. Similarly, the highest number of people using the same cabin is 4. They are using cabin number \"C23 C25 C27\".\n",
    "\n",
    "We also see that 644 people were embarked from port \"S\".\n",
    "\n",
    "Among 891 rows, 577 were Male and the rest were Female.\n",
    "\n",
    "We use info() method to see more information of our train dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking into the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total rows and columns (testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we see that the test data has 418 rows and 11 columns.\n",
    "\n",
    "    Train data rows = 891\n",
    "\n",
    "    Test data rows = 418\n",
    "\n",
    "    Total rows = 891+418 = 1309\n",
    "\n",
    "We can see that around 2/3 of total data is set as Train data and around 1/3 of total data is set as Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing Dataset (test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There are missing entries for Age in Test dataset as well.\n",
    "\n",
    "Out of 418 rows in Test dataset, only 332 rows have Age value.\n",
    "\n",
    "Cabin values are also missing in many rows. Only 91 rows out ot 418 have values for Cabin column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Visulazation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between Features and Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = train[train['Survived']==1]\n",
    "not_survived=train[train['Survived']==0]\n",
    "\n",
    "print(\"Survived: %i (%.1f%%)\"%(len(survived),float(len(survived))/len(train)*100.0))\n",
    "print(\" Not Survived: %i (%.1f%%)\"%(len(not_survived),float(len(not_survived))/len(train)*100.0))\n",
    "print (\"Total: %i\"%len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pclass vs Survical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Pclass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('Pclass').Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Pclass','Survived']].groupby(['Pclass'],as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass',y='Survived',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('Sex').Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Sex','Survived']].groupby(['Sex'],as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Sex',y='Survived',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pclass & Sex vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.crosstab(train['Pclass'],train['Sex'])\n",
    "print(tab)\n",
    "tab.div(tab.sum(1).astype(float),axis=0).plot(kind=\"bar\",stacked=True)\n",
    "plt.xlabel('Pclass')\n",
    "plt.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Sex','Survived',hue='Pclass',size=4,aspect=2,data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, it can be seen that:\n",
    "\n",
    "    *Women from 1st and 2nd Pclass have almost 100% survival chance.\n",
    "    *Men from 2nd and 3rd Pclass have only around 10% survival chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pclass,Sex & Embarked vs. Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot(x='Pclass',y='Survived',hue='Sex',col='Embarked',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, it can be seen that:\n",
    "\n",
    "    1.Almost all females from Pclass 1 and 2 survived.\n",
    "    2.Females dying were mostly from 3rd Pclass.\n",
    "    3.Males from Pclass 1 only have slightly higher survival chance than Pclass 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embarked vs Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('Embarked').Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Embarked','Survived']].groupby(['Embarked'],as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Embarked',y='Survived',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parch vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Parch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('Parch').Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Parch',y='Survived',ci=None,data=train)\n",
    "# ci=None will hide the error bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sibsp vs Survial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.SibSp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('SibSp').Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['SibSp','Survived']].groupby(['SibSp'],as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='SibSp',y='Survived',ci=None,data=train)\n",
    "#ci=None will hide the error bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "sns.violinplot(x=\"Embarked\", y=\"Age\", hue=\"Survived\", data=train, split=True, ax=ax1)\n",
    "sns.violinplot(x=\"Pclass\", y=\"Age\", hue=\"Survived\", data=train, split=True, ax=ax2)\n",
    "sns.violinplot(x=\"Sex\", y=\"Age\", hue=\"Survived\", data=train, split=True, ax=ax3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "From Pclass violinplot, we can see that:\n",
    "\n",
    "    1.1st Pclass has very few children as compared to other two classes.\n",
    "    2.1st Plcass has more old people as compared to other two classes.\n",
    "    3.Almost all children (between age 0 to 10) of 2nd Pclass survived.\n",
    "    4.Most children of 3rd Pclass survived.\n",
    "    5.Younger people of 1st Pclass survived as compared to its older people.\n",
    "\n",
    "From Sex violinplot, we can see that:\n",
    "\n",
    "    1.Most male children (between age 0 to 14) survived.\n",
    "    2.Females with age between 18 to 40 have better survival chance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_survived = train[train['Survived']==1]\n",
    "total_not_survived = train[train['Survived']==0]\n",
    "male_survived = train[(train['Survived']==1) & (train['Sex']==\"male\")]\n",
    "female_survived = train[(train['Survived']==1) & (train['Sex']==\"female\")]\n",
    "male_not_survived = train[(train['Survived']==0) & (train['Sex']==\"male\")]\n",
    "female_not_survived = train[(train['Survived']==0) & (train['Sex']==\"female\")]\n",
    "\n",
    "plt.figure(figsize=[15,5])\n",
    "plt.subplot(111)\n",
    "sns.distplot(total_survived['Age'].dropna().values, bins=range(0, 81, 1), kde=False, color='blue')\n",
    "sns.distplot(total_not_survived['Age'].dropna().values, bins=range(0, 81, 1), kde=False, color='red', axlabel='Age')\n",
    "\n",
    "plt.figure(figsize=[15,5])\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.distplot(female_survived['Age'].dropna().values, bins=range(0, 81, 1), kde=False, color='blue')\n",
    "sns.distplot(female_not_survived['Age'].dropna().values, bins=range(0, 81, 1), kde=False, color='red', axlabel='Female Age')\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.distplot(male_survived['Age'].dropna().values, bins=range(0, 81, 1), kde=False, color='blue')\n",
    "sns.distplot(male_not_survived['Age'].dropna().values, bins=range(0, 81, 1), kde=False, color='red', axlabel='Male Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above figures, we can see that:\n",
    "\n",
    "1.Combining both male and female, we can see that children with age between 0 to 5 have better chance of survival.\n",
    "2.Females with age between \"18 to 40\" and \"50 and above\" have higher chance of survival.\n",
    "3.Males with age between 0 to 14 have better chance of survival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.heatmap(train.drop('PassengerId',axis=1).corr(), vmax=0.6, square=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Correlating Features\n",
    "\n",
    "Heatmap of Correlation between different features:\n",
    "\n",
    "    Positive numbers = Positive correlation, i.e. increase in one feature will increase the other feature & vice-versa.\n",
    "\n",
    "    Negative numbers = Negative correlation, i.e. increase in one feature will decrease the other feature & vice-versa.\n",
    "\n",
    "In our case, we focus on which features have strong positive or negative correlation with the Survived feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "In this section, we select the appropriate features to train our classifier. Here, we create new features based on existing features. We also convert categorical features into numeric form.\n",
    "### Name Feature\n",
    "\n",
    "Let's first extract titles from Name column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = [train,test] #combining train and test dataset\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title']=dataset.Name.str.extract('([A-Za-z]+)\\.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, we have added a new column named Title in the Train dataset with the Title present in the particular passenger name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(train['Title'],train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['Title']= dataset['Title'].replace(['Lady','Countess','Capt','Col',\\\n",
    "                            'Don','Dr','Major','Rev','Sir','Jonkheer','Dona'],'Other')\n",
    "    dataset['Title']=dataset['Title'].replace('Mlle','Miss')\n",
    "    dataset['Title']=dataset['Title'].replace('Ms','Miss')\n",
    "    dataset['Title']=dataset['Title'].replace('Mme','Mrs')\n",
    "train[['Title','Survived']].groupby(['Title'],as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Other\": 5}\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex Feature\n",
    "\n",
    "We convert the categorical value of Sex into numeric. We represent 0 as female and 1 as male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked Feature\n",
    "\n",
    "There are empty values for some rows for Embarked column. The empty values are represented as \"nan\" in below list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['Embarked']= dataset['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now convert the categorical value of Embarked into numeric. We represent 0 as S, 1 as C and 2 as Q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    #print(dataset.Embarked.unique())\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Feature\n",
    "\n",
    "We first fill the NULL values of Age with a random number between (mean_age - std_age) and (mean_age + std_age).\n",
    "\n",
    "We then create a new column named AgeBand. This categorizes age into 5 different age range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    \n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "train['AgeBand'] = pd.cut(train['Age'], 5)\n",
    "\n",
    "print (train[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare Feature\n",
    "\n",
    "Replace missing Fare values with the median of Fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['FareBand'] = pd.qcut(train['Fare'], 4)\n",
    "print (train[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SibSp & Parch Feature\n",
    "\n",
    "Combining SibSp & Parch feature, we create a new feature named FamilySize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] +  dataset['Parch'] + 1\n",
    "\n",
    "print (train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About data shows that:\n",
    "\n",
    "    1.Having FamilySize upto 4 (from 2 to 4) has better survival chance.\n",
    "    2.FamilySize = 1, i.e. travelling alone has less survival chance.\n",
    "    3.Large FamilySize (size of 5 and above) also have less survival chance.\n",
    "\n",
    "Let's create a new feature named IsAlone. This feature is used to check how is the survival chance while travelling alone as compared to travelling with family.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    \n",
    "print (train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that travelling alone has only 30% survival chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "We drop unnecessary columns/features and keep only the useful ones for our experiment. Column PassengerId is only dropped from Train set because we need PassengerId in Test set while creating Submission file to Kaggle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_drop = ['Name', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'FamilySize']\n",
    "train = train.drop(features_drop, axis=1)\n",
    "test = test.drop(features_drop, axis=1)\n",
    "train = train.drop(['PassengerId', 'AgeBand', 'FareBand'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('Survived', axis=1)\n",
    "y_train = train['Survived']\n",
    "X_test = test.drop(\"PassengerId\", axis=1).copy()\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many classifying algorithms present. Among them, we choose the following Classification algorithms for our problem:\n",
    "\n",
    "    1.Logistic Regression\n",
    "    2.Support Vector Machines (SVC)\n",
    "    3.Linear SVC\n",
    "    4.k-Nearest Neighbor (KNN)\n",
    "    5.Decision Tree\n",
    "    6.Random Forest\n",
    "    7.Naive Bayes (GaussianNB)\n",
    "    8.Perceptron\n",
    "    9.Stochastic Gradient Descent (SGD)\n",
    "\n",
    "Here's the training and testing procedure:\n",
    "\n",
    "    First, we train these classifiers with our training data.\n",
    "\n",
    "    After that, using the trained classifier, we predict the Survival outcome of test data.\n",
    "\n",
    "    Finally, we calculate the accuracy score (in percentange) of the trained classifier.\n",
    "\n",
    "Please note: that the accuracy score is generated based on our training dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Choosing Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Classifier Modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred_log_reg =clf.predict(X_test)\n",
    "acc_log_reg = round( clf.score(X_train, y_train) * 100, 2)\n",
    "print (str(acc_log_reg) + ' percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_svc = clf.predict(X_test)\n",
    "acc_svc = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (acc_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_linear_svc = clf.predict(X_test)\n",
    "acc_linear_svc = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (acc_linear_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 3)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_knn = clf.predict(X_test)\n",
    "acc_knn = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (acc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_decision_tree = clf.predict(X_test)\n",
    "acc_decision_tree = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (acc_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_random_forest = clf.predict(X_test)\n",
    "acc_random_forest = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (acc_random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_gnb = clf.predict(X_test)\n",
    "acc_gnb = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (acc_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Perceptron(max_iter=5, tol=None)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_perceptron = clf.predict(X_test)\n",
    "acc_perceptron = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (acc_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(max_iter=5, tol=None)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_sgd = clf.predict(X_test)\n",
    "acc_sgd = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (acc_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_random_forest_training_set = clf.predict(X_train)\n",
    "acc_random_forest = round(clf.score(X_train, y_train) * 100, 2)\n",
    "print (\"Accuracy: %i %% \\n\"%acc_random_forest)\n",
    "\n",
    "class_names = ['Survived', 'Not Survived']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_train, y_pred_random_forest_training_set)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print ('Confusion Matrix in Numbers')\n",
    "print (cnf_matrix)\n",
    "print ('')\n",
    "\n",
    "cnf_matrix_percent = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print ('Confusion Matrix in Percentage')\n",
    "print (cnf_matrix_percent)\n",
    "print ('')\n",
    "\n",
    "true_class_names = ['True Survived', 'True Not Survived']\n",
    "predicted_class_names = ['Predicted Survived', 'Predicted Not Survived']\n",
    "\n",
    "df_cnf_matrix = pd.DataFrame(cnf_matrix, \n",
    "                             index = true_class_names,\n",
    "                             columns = predicted_class_names)\n",
    "\n",
    "df_cnf_matrix_percent = pd.DataFrame(cnf_matrix_percent, \n",
    "                                     index = true_class_names,\n",
    "                                     columns = predicted_class_names)\n",
    "\n",
    "plt.figure(figsize = (15,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "sns.heatmap(df_cnf_matrix, annot=True, fmt='d')\n",
    "\n",
    "plt.subplot(122)\n",
    "sns.heatmap(df_cnf_matrix_percent, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Models\n",
    "\n",
    "Let's compare the accuracy score of all the classifier models used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Support Vector Machines', 'Linear SVC', \n",
    "              'KNN', 'Decision Tree', 'Random Forest', 'Naive Bayes', \n",
    "              'Perceptron', 'Stochastic Gradient Decent'],\n",
    "    \n",
    "    'Score': [acc_log_reg, acc_svc, acc_linear_svc, \n",
    "              acc_knn,  acc_decision_tree, acc_random_forest, acc_gnb, \n",
    "              acc_perceptron, acc_sgd]\n",
    "    })\n",
    "\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, we can see that Decision Tree and Random Forest classfiers have the highest accuracy score.\n",
    "\n",
    "Among these two, we choose Random Forest classifier as it has the ability to limit overfitting as compared to Decision Tree classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission File to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": y_pred_random_forest\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.to_csv('Titanic_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
